\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{lstlisting} {0}

\chapter{\framework{}: a framework for virtual exocentric vision systems}
\label{rear}
\minitoc

In this section we will describe \framework{} - 
\textit{Rear Exocentric Augmented Reality}, a framework 
for the development of virtual exocentric vision systems.
\\
It has been written in C++, following an object-oriented 
approach, and implements the minimal set of tools and functionalities 
needed to create representations of a mobile robot in its environment 
through the use of augmented reality techniques, as described in 
section \ref{exo}.
\\
For what concerns graphics, \framework{} relies on OpenGL.
It makes use of three software components: a \textit{camera}, 
a 3D model of the \textit{robot} itself and a \textit{texture}.
\\
The camera provides the user with a view of the OpenGL space 
from a certain point-of-view and with a certain field-of-view. 
It identifies a \textit{viewing frustum} - as shown in figure 
\ref{fig:openglspace} - whose volume corresponds to the 
portion of OpenGL space displayed on the user's screen.
\\
To give the user the illusion of seeing the robot from an 
external point-of-view, the 3d model of the robot is drawn 
within the viewing frustum, while the more distant frustum base 
is applied a texture displaying a picture previously 
captured from the robot's egocentric camera.
\\
An example of what a user sees is showed in figure \ref{fig:snap}.

\begin{figure}[!h]
  \begin{center}
    \includegraphics[width=300pt]{img/camera_frustum_scheme.png}
    \caption{The OpenGL space}
    \label{fig:openglspace}
  \end{center}
\end{figure}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[width=300pt]{img/rear_snapshot_large.jpg}
    \caption{A snapshot from a \framework{}-based application}
    \label{fig:snap}
  \end{center}
\end{figure}

Main issues in the approach we have just described are 1. 
\textit{where} to draw the robot within the viewing frustum 
and 2. \textit{which} of the captured images is to be used 
as background.
\\
For what concerns the first issue, one can intuitively guess 
that the simplest way to determine the robot position 
within the frustum is to know the current robot position 
and orientation and the position and orientation of the egocentric 
camera when the snapshot was taken and, then, to set the 
position of the 3d model of the robot and the point-of-view 
of the camera accordingly.
Well, that's what \framework{} does.
\\
Therefore, to run, every \framework{} concrete implementation 
needs, at least:

\begin{itemize}
  \item a set of snapshots captured from the robot egocentric camera, 
    together with the robot position at the time it was taken
  \item the robot's current position
\end{itemize}

Such data is retrieved every time the operator, using the 
interface provided by \framework{} itself, sends a 
motion command to the robot.
\\
After collecting new data, which include new robot status and
the associated egocentric camera image, \framework{} chooses 
an image to set as background and draw the robot model within 
the frustum. So, for what concerns issue no. 2, as already 
underlined in \cite{sugimoto}, let us say that there is not 
a \textit{unique} way to determine which image is to be set 
as background, since different image selection algorithms 
would differently affect user perceptions and. We will have a 
deeper look at some image selection algorithms in section
\ref{rear:interfaces:iimageselector}.
\\
Finally, the overall execution loop is resumed by the flowchart 
showed in figure \ref{fig:overall_diagram}.
\\
\begin{figure}[!h]
  \begin{center}
    \includegraphics[width=\textwidth]{img/overall_diagram.jpeg}  %robot pic
    \caption{Application flowchart}
    \label{fig:overall_diagram}
  \end{center}
\end{figure}

\clearpage
\input{rear_framework/class_diagram}
\clearpage
\input{rear_framework/classes}
\clearpage
\input{rear_framework/interfaces}
