\section{Morduc Simulator Log}
\label{log:morduc_simulator}

An exocentric vision systems performs at its best 
when there's a large static space where the robot can move in. Since 
the real robot can not be easily teleguided in wide 
environment because of its size and the lack of a large 
room in Catania, where the robot is situated, a simulator 
has been used to reproduce the best set of data. The 
simulator can be thought of as a server, which receives 
requests and returns responses: the first are the commands 
sent by the user to move the robot, the latter the 
egocentric images and the robot position data.
\\
Furthermore, with a simulator is extremely easy to 
change the environment where the robot is teleguided, 
so we can test the exocentric vision with an infinite 
number of environments without physically moving the 
robot in different places. In this way software 
development of exocentric vision can be faster, because 
it is simple and immediate to establish several test cases.
\\
The first simulator adopted was \textit{Rosen} (\cite{rosen}). Written in 
\textit{Erlang} \cite{erlang}, \textit{Rosen} has been developed at
the \textit{University of Catania} in order to simulate the behaviour of
autonomous mobile robots (AMRs).
\\
\textit{Rosen} has been used as test bench for robots taking part in 
the \textit{Eurobot} competition \cite{eurobot}, and hence, 
for robots with completely different features from the ones of \morduc{}. 
\\
As soon as we realized \textit{Rosen} does not meet our needs, 
we started looking for a more suitable simulator.
\\
In 2006, at the \textit{Aalborg University}, Filippo 
Privitera wrote a simulator specifically intended for 
the \morduc{} platform \cite{privitera}. 
\\
Such a simulator reproduces the \morduc{} itself (actually a 
3d model of it) situated in a customizable room: the position 
of walls can be specified by the user, by giving 
the simulator a black and white bitmap image with the room 
planimetry, to build the whole environment from. 
\\
Besides, Privitera's simulator allows to enable the 
stereoscopic vision, with anaglyph or polarized method (both 
types are applied on the egocentric camera). Other informations 
like the number of collisions or the robot distance from the 
nearest obstacle are provided by simulator.
\\
The simulator was written using the Microsoft Foundation Class
(MFC) framework and has been used for testing user ability in
tele operating driving a robot, in comparison with the actual 
robot to quantify the differences between the two facilities. 
\\
With a simulator specifically built for the \morduc{} robot, it 
was not difficult to edit the source code to obtain what we 
needed. First of all, we needed to record data about egocentric 
vision and robot status, because they are the input value 
of the exocentric vision simulator. In order to achieve this, 
we edited the source code to allows the user to store data: by 
pressing the 'P' key keyboard the actual information (e.g. the 
actual camera image and robot status) are recorded in log files.
\\
Every session in Privitera's simulator has its own identifier 
(a integer number). When the 'P' key is pressed the simulator 
write a new line in the text file named

\begin{center}
  \textit{data\_$\langle$number of session$\rangle$.txt}
\end{center}

creating the file if it does not 
exist. Each line contains four float number values, with the 
following meaning:

\begin{enumerate}
\item x coordinate
\item y coordinate
\item theta value (in radiants)
\item timestamp
\end{enumerate}

where the timestamp refers to the beginning of the simulation.
\\
Beside the text file there are several PNG images, each for every 
line written in \textit{data\_$\langle$number of 
session$\rangle$.txt}.
These files are named

\begin{center}
  \textit{screenshot\_$\langle$number of 
    session$\rangle$\_$\langle$timestamp$\rangle$.png}
\end{center}

where the 
number of session indicates for every screenshot 
- i.e. the egocentric vision - the proper text file, and the 
timestamp the line with the associated status of the robot.
\\
The software which implement the exocentric vision control 
will look for text and image files related to a specific 
session, in order to read the necessary input and draw the 
robot correctly. It must be able to choose the right image 
to use as background, among those previously read; to draw 
the robot over the background in the right position and 
orientation, depending on its route; to prevent or signal 
collisions to the user, and so on.
