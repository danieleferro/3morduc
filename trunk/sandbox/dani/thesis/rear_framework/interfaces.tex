\section{Interfaces}
\label{rear:interfaces}

This section will describe interfaces that
makes \framework{} a real framework. Again, we refer
to figure
\ref{fig:class_diagram} for the complete system
architecture.

\subsection{The IDataLogic interface}
\label{rear:interfaces:idatalogic}

\texttt{IDataLogic} provides a communication interface 
with the robot, decoupling the \texttt{DataManager} 
from the actual technology used to interact with it 
and to collect data. Its declaration is:
\\ 
\begin{lstlisting}[caption={\texttt{IDataLogic} declaration}, label={code:idatalogic}]
class IDataLogic {
 public:
  virtual void Command(int) = 0;
  virtual void RetrieveData(robot_data *) = 0;
  virtual void SelectImage(robot_data *, image_data *,
			   IImageSelector *) = 0;
};
\end{lstlisting}

When implementing a class of type \texttt{IDataLogic}
programmers should keep in mind the followings:

\begin{itemize}
  \item \texttt{RetrieveData()} must fill the passed 
    \texttt{robot\_data} structure with the retrieved position and
    orientation of the robot. It must also keep track of 
    all retrieved snapshots.
  \item \texttt{SelectImage()} is passed the robot's current 
    position and orientation and an object of type 
    \texttt{IImageSelector}. In order to obtain the image 
    to set as background (whose metadata will be saved 
    in the \texttt{image\_data} structure), an 
    invocation of the \texttt{IImageSelector::ChooseImage()}
    is required (for further details, see chapter
    \ref{rear:interfaces:iimageselector}).
\end{itemize}

A skeleton of \texttt{RetrieveData()}, \texttt{Command()} and 
\texttt{SelectImage()} is presented in listing 
\ref{code:idatalogic_skeleton}.
\\
\begin{lstlisting}[caption={\texttt{IDataLogic} methods skeleton},
    label={code:idatalogic_skeleton}]
void DataLogic::RetrieveData( robot_data * data )
{
  // actually retrieve new data

  // store the collected snapshot into an
  // internal data structure
  
  data -> x = retrieved_robot_data.x;
  data -> y = retrieved_robot_data.y;
  data -> theta = retrieved_robot_data.theta; 
  data -> time = retrieved_robot_data.time;

  return;
}

void DataLogic::SelectImage( robot_data * robot_status, 
                             image_data * bg_image_data,
			     IImageSelector * calculator )
{
  // say we have used a vector to store 
  // metadata of the collected snapshots, 
  // then we could invoke the ChooseImage method

  selector -> ChooseImage( robot_status, bg_image_data, 
                             &_images_collection );
}

void DataLogic::Command( int command )
{
  // send command defined with the
  // int value to the robot
}

\end{lstlisting}


\subsection{The IImageSelector interface}
\label{rear:interfaces:iimageselector}

Last, but not least, the \texttt{IImageSelector} interface
defines the type of classes that encapsulate an image 
selection algorithm. It declares just a method, that 
we have already encountered in the previous section:
\\
\begin{lstlisting}[caption={\texttt{IImageSelector} declaration}, 
    label={code:iimageselector}]
class IImageSelector
{
 public:
  virtual void ChooseImage(robot_data *, image_data *, 
                           std::vector<image_data> *) = 0;
};
\end{lstlisting}

\texttt{ChooseImage()} is passed the current robot position and
orientation and a vector of images metadata. It will process them 
and will fill the passed \texttt{image\_data} structured fields 
with the metadata of the selected image.
\\
Say we want to define a class that implements the selection 
method number two presented in \cite{sugimoto}. That selection method
chooses the image taken as near as possible to the robot
current position.
\\
The \texttt{Calculate()} function, defined within the concrete class
implementing \texttt{IImageSelector} interface,
estimates the euclidean distance between robot and a generic image.
If we decided to choose the closest image to the robot, we would
show the egocentric vision, because the algorithm would always
select the image coupled with distance equal to zero. We remember
that the egocentric vision image is always present in our images' set.
\\
In order to not show only the egocentric vision, the \texttt{ChooseImage()}
does not return the image coupled with the minimum distance, but the one
(if available) with the minimum distance greater than zero.
\\
We could, then, write:
\\
\begin{lstlisting}[caption={A possible \texttt{ChooseImage} implementation}, label={code:chooseimage_impl}]
class SpacialMetricSelector : public IImageSelector
{
  public:
  void ChooseImage(robot_data *, image_data *, 
                   std::vector<image_data> *);
};


void SpacialMetricSelector::
      ChooseImage( robot_data * robot_status, 
                   image_data * bg_image_data,
		   std::vector<image_data> * 
                      _images_collection)
{

  float distances[_images_collection->size()];
  float min;

  // calculate the distance for each stored image
  int i = 0;
  for (std::vector<image_data>::iterator it =
	 _images_collection->begin();
       it != _images_collection->end();
       it++)
    {
      distances[i] = Calculate(robot_status, &*it);
      i++;
    }

  // find the minimum distance
  i = 0;
  min = distances[0];
  for (int j = 1; j < _images_collection->size(); j++)
    {
      if ( ( distances[j] < min && min != 0) || 
           ( distances[j] > min && min == 0)    )
	{
	  i = j;
	  min = distances[j];
	}
    }

  // return the selected image data
  bg_image_data->x = (*_images_collection)[i].x;
  bg_image_data->y = (*_images_collection)[i].y;
  bg_image_data->theta = (*_images_collection)[i].theta;
  bg_image_data->time = (*_images_collection)[i].time;
}
\end{lstlisting}
